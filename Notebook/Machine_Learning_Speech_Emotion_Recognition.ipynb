{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# <center> Speech & Song Emotion Recognition Using Multilayer Perceptron and Standard Vector Machine  </center>\n",
    "\n",
    "## Behzad Javaheri\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "### This notebook contains all the steps taken to process. These are:\n",
    "\n",
    "#### 1. Description of the dataset\n",
    "#### 2. Importing required libraries\n",
    "#### 3. Predictor extraction\n",
    "#### 4. Data exploration and visualisation of extracted features\n",
    "#### 5. Model constructions using SVM and MLP algorithms\n",
    "#### 6. Data augmentation and address data imbalance. Optimised SVM and MLP will run on the augment dataset\n",
    "#### 7. Data split by vocal channel into speech and song. Optimised SVM and MLP will run on the split datasets.\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AztUA74EerMQ"
   },
   "source": [
    "### 1. Description of dataset\n",
    "#### The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) \n",
    "\n",
    "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) was utilised in this study. The audio files recorded in speech or song vocal channels by 24 (12 males, 12 females) and 23 (12 males, 11 females) actors in each vocal channel, respectively are available in .wav format. The emotions expressed within the speech channel include calm, happy, sad, angry, fearful, disgust and surprise, and for the song, channel include calm, happy, sad, angry, and fearful. The speech channel has 1440 (60 trials per actor x 24 actors) and song channel 1012 (44 trials per actor x 23 actors), providing 2452 audio files. The naming system for these audio files used are as follow: So for convenience, here's the filename identifiers as per the official RAVDESS website:\n",
    "\n",
    "* Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "* Vocal channel (01 = speech, 02 = song).\n",
    "* Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "* Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "* Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "* Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "* Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqlY-_LUpD3l"
   },
   "source": [
    "### 2. Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fyYSbcJjy7i"
   },
   "outputs": [],
   "source": [
    "from timeit import Timer\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile\n",
    "\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "import time\n",
    "from random import shuffle\n",
    "from scipy import stats\n",
    "\n",
    "import IPython.display as ipd \n",
    "import plotly.io as pio\n",
    "from matplotlib.pyplot import specgram\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import seaborn as sns\n",
    "# to improve matplotlib graphs\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "pio.renderers.default='notebook'\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, train_test_split, cross_val_predict, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, plot_precision_recall_curve,accuracy_score \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from joblib import dump, load\n",
    "\n",
    "import yellowbrick as yb\n",
    "from yellowbrick.classifier import ClassificationReport, PrecisionRecallCurve, ClassPredictionError, ROCAUC, ConfusionMatrix\n",
    "from yellowbrick.regressor import PredictionError, ResidualsPlot\n",
    "from yellowbrick.model_selection import LearningCurve, ValidationCurve, FeatureImportances, CVScores\n",
    "from yellowbrick.style.rcmod import set_aesthetic, set_palette\n",
    "\n",
    "from pydiogment.auga import fade_in_and_out\n",
    "from pydiogment.augf import change_tone\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings('ignore')\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShlEahDIzwIf"
   },
   "source": [
    "### 3. Predictor extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QufSKr1ksJc"
   },
   "source": [
    "Here we define a function to extract 5 predictors detailed below from these audio files. \n",
    "\n",
    "* mfcc: Mel Frequency Cepstral Coefficient, represents the short-term power spectrum of a sound\n",
    "* chroma: Pertains to the 12 different pitch classes\n",
    "* mel: Mel Spectrogram Frequency\n",
    "* Contrast \n",
    "* Tonnetz (tonnetz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 The function for predictor extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwB6D_vLpOoR"
   },
   "outputs": [],
   "source": [
    "#Source: https://github.com/MasazI/audio_classification/blob/master/features.py\n",
    "def extract_feature(file_name, mfcc, chroma, mel, tonnetz, contrast):\n",
    "        X, sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
    "        result = np.array([])\n",
    "        if chroma or contrast:\n",
    "            stft = np.abs(librosa.stft(X))\n",
    "            result = np.array([])\n",
    "        if mfcc:\n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result = np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, mel))\n",
    "        if contrast:\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, contrast))\n",
    "        if tonnetz:\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "            result = np.hstack((result, tonnetz))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xKzPyVcjvyT"
   },
   "source": [
    "#### 3.2 Assigning emotions to numerical correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgwcKBQzpdgM"
   },
   "outputs": [],
   "source": [
    "# Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "# Emotions to observe\n",
    "observed_emotions = ['neutral','calm','happy', 'sad','angry','fearful','disgust','surprised']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VjDiYuC3G-D"
   },
   "source": [
    "#### 3.3 Defining a function that will ieterate through all audio files for predictor extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2axyBFDqI1A"
   },
   "outputs": [],
   "source": [
    "## The audio files can be downloaded from:\n",
    "## Song files from: https://zenodo.org/record/1188976/files/Audio_Song_Actors_01-24.zip?download=1\n",
    "## Speech files: https://zenodo.org/record/1188976/files/Audio_Speech_Actors_01-24.zip?download=1\n",
    "## These downloaded folders need to be combined prior to predictor extractions\n",
    "\n",
    "def load_data():\n",
    "    X = []\n",
    "    gender = []\n",
    "    channel = []\n",
    "    y =[]\n",
    "    actor=[]\n",
    "    for file in glob.glob('..\\\\data\\\\RAV\\\\Actor_*\\\\*.wav'):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        part = file_name.split('.')[0].split('-')\n",
    "        #actor.append(int(part[6]))\n",
    "        #bg = int(part[6])\n",
    "               \n",
    "        temp1 = int(part[6])\n",
    "        if temp1%2 == 0:\n",
    "            temp1 = 0 # for females\n",
    "        else:\n",
    "            temp1 = 1 # for males\n",
    "        gender.append(temp1)\n",
    "        \n",
    "        temp2 = int(part[1])\n",
    "        if temp2%2 == 0:\n",
    "            temp2 = 2 # for song\n",
    "        else:\n",
    "            temp2 = 1 # for speech\n",
    "        channel.append(temp2)\n",
    "        \n",
    "        # we allow only AVAILABLE_EMOTIONS we set\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "            \n",
    "         # extract speech features\n",
    "        feature=extract_feature(file, \n",
    "                                mfcc=True, \n",
    "                                chroma=True, \n",
    "                                mel=True, \n",
    "                                tonnetz=True, \n",
    "                                contrast=True)\n",
    "    \n",
    "        X.append(feature)\n",
    "        y.append(emotion)\n",
    "\n",
    "    return {\"X\":X, \"channel\":channel, \"gender\":gender, \"y\":y, }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKhGTlqpqOAr"
   },
   "source": [
    "#### 3.4 Performing predictor extraction using above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCqGp5MeWzil"
   },
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "\n",
    "# Defining different elements extracted\n",
    "X = pd.DataFrame(data[\"X\"])\n",
    "channel = pd.DataFrame(data[\"channel\"],columns=['channel'])\n",
    "gender = pd.DataFrame(data[\"gender\"],columns=['gender']) \n",
    "y = pd.DataFrame(data[\"y\"],columns=['emotions'])\n",
    "\n",
    "###Observe the shape of the training and testing datasets:\n",
    "\n",
    "# number of samples in training data\n",
    "print(\"[+] Number of training samples:\", X.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", y.shape[0])\n",
    "# number of samples in channel data\n",
    "print(\"[+] Number of testing samples:\", channel.shape[0])\n",
    "# number of samples in gender data\n",
    "print(\"[+] Number of testing samples:\", gender.shape[0])\n",
    "\n",
    "# Get the number of features extracted\n",
    "print(f'Features extracted: {X.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Saving the extracted variables into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X, channel, gender, y], axis =1)\n",
    "data.to_csv(\"RAV_extracted_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R980EURTYmYs"
   },
   "source": [
    "### 4. Data exploration and visualisation of extracted features\n",
    "\n",
    "In this step two visulisation will be performed to display audio files waveform and extracted Mel Spectrogram that will be used as a predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Visulisation of waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Visualisation of waveform for all emotions #####################################\n",
    "sns.set_context('paper', font_scale=2)\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-01-01-01-01-01.wav') as audio:\n",
    "    waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.subplot(3, 2, 1)\n",
    "    librosa.display.waveplot(waveform, sr=sample_rate)\n",
    "    plt.title('Neutral')\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-02-01-02-01-01.wav') as audio:\n",
    "    waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "    plt.subplot(3, 2, 2)\n",
    "    librosa.display.waveplot(waveform, sr=sample_rate)\n",
    "    plt.title('Calm')\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-03-01-01-01-01.wav') as audio:\n",
    "    waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.subplot(3, 2, 3)\n",
    "    librosa.display.waveplot(waveform, sr=sample_rate)\n",
    "    plt.title('Happy')\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-04-01-01-01-01.wav') as audio:\n",
    "    waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "    plt.subplot(3, 2, 4)\n",
    "    librosa.display.waveplot(waveform, sr=sample_rate)\n",
    "    plt.title('Sad')\n",
    "    \n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-05-01-01-01-01.wav') as audio:\n",
    "    waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.subplot(3, 2, 5)\n",
    "    librosa.display.waveplot(waveform, sr=sample_rate)\n",
    "    plt.title('Angry')\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-06-01-01-01-01.wav') as audio:\n",
    "    waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "    plt.subplot(3, 2, 6)\n",
    "    librosa.display.waveplot(waveform, sr=sample_rate)\n",
    "    plt.title('Fearful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Visualisation of Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://towardsdatascience.com/speech-emotion-recognition-using-ravdess-audio-dataset-ce19d162690\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-01-01-01-01-01.wav') as audio:\n",
    "    neutral_waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-02-01-01-01-01.wav') as audio:\n",
    "    calm_waveform = audio.read(dtype=\"float32\")\n",
    "    # same sample rate\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-03-01-01-01-01.wav') as audio:\n",
    "    happy_waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-04-01-01-01-01.wav') as audio:\n",
    "    sad_waveform = audio.read(dtype=\"float32\")\n",
    "    # same sample rate\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-05-01-01-01-01.wav') as audio:\n",
    "    angry_waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-06-01-01-01-01.wav') as audio:\n",
    "    fearful_waveform = audio.read(dtype=\"float32\")\n",
    "    # same sample rate\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-07-01-01-01-01.wav') as audio:\n",
    "    disgust_waveform = audio.read(dtype=\"float32\")\n",
    "    sample_rate = audio.samplerate\n",
    "\n",
    "with soundfile.SoundFile('..\\\\data\\\\RAV\\\\actor_01\\\\03-01-08-01-01-01-01.wav') as audio:\n",
    "    surprised_waveform = audio.read(dtype=\"float32\")\n",
    "    # same sample rate\n",
    "\n",
    "sns.set_context('paper', font_scale=3)\n",
    "melspectrogram = librosa.feature.melspectrogram(y=neutral_waveform, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.subplot(2, 4, 1)\n",
    "librosa.display.specshow(librosa.power_to_db(S=melspectrogram, ref=np.mean),y_axis='mel',fmax=8000, x_axis='time', norm=Normalize(vmin=-20,vmax=20))\n",
    "#plt.colorbar(format='%+2.0f dB',label='Amplitude')\n",
    "plt.xlim(2,6)\n",
    "plt.ylabel('Mels')\n",
    "plt.title('Neutral')\n",
    "\n",
    "melspectrogram = librosa.feature.melspectrogram(y=calm_waveform, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "plt.subplot(2, 4, 2)\n",
    "librosa.display.specshow(librosa.power_to_db(S=melspectrogram, ref=np.mean),y_axis='mel',fmax=8000, x_axis='time', norm=Normalize(vmin=-20,vmax=20))\n",
    "#plt.colorbar(format='%+2.0f dB',label='Amplitude')\n",
    "plt.xlim(2,6)\n",
    "plt.ylabel('Mels')\n",
    "plt.title('Calm')\n",
    "plt.tight_layout()\n",
    "\n",
    "melspectrogram = librosa.feature.melspectrogram(y=happy_waveform, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "plt.subplot(2, 4, 3)\n",
    "librosa.display.specshow(librosa.power_to_db(S=melspectrogram, ref=np.mean),y_axis='mel',fmax=8000, x_axis='time', norm=Normalize(vmin=-20,vmax=20))\n",
    "#plt.colorbar(format='%+2.0f dB',label='Amplitude')\n",
    "plt.xlim(2,6)\n",
    "plt.ylabel('Mels')\n",
    "plt.title('Happy')\n",
    "\n",
    "melspectrogram = librosa.feature.melspectrogram(y=sad_waveform, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "plt.subplot(2, 4, 4)\n",
    "librosa.display.specshow(librosa.power_to_db(S=melspectrogram, ref=np.mean),y_axis='mel',fmax=8000, x_axis='time', norm=Normalize(vmin=-20,vmax=20))\n",
    "plt.colorbar(format='%+2.0f dB',label='Amplitude')\n",
    "plt.xlim(2,6)\n",
    "plt.ylabel('Mels')\n",
    "plt.title('Sad')\n",
    "plt.tight_layout()\n",
    "\n",
    "melspectrogram = librosa.feature.melspectrogram(y=angry_waveform, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "plt.subplot(2, 4, 5)\n",
    "librosa.display.specshow(librosa.power_to_db(S=melspectrogram, ref=np.mean),y_axis='mel',fmax=8000, x_axis='time', norm=Normalize(vmin=-20,vmax=20))\n",
    "#plt.colorbar(format='%+2.0f dB',label='Amplitude')\n",
    "plt.xlim(2,6)\n",
    "plt.ylabel('Mels')\n",
    "plt.title('Angry')\n",
    "\n",
    "melspectrogram = librosa.feature.melspectrogram(y=fearful_waveform, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "plt.subplot(2, 4, 6)\n",
    "librosa.display.specshow(librosa.power_to_db(S=melspectrogram, ref=np.mean),y_axis='mel',fmax=8000, x_axis='time', norm=Normalize(vmin=-20,vmax=20))\n",
    "#plt.colorbar(format='%+2.0f dB',label='Amplitude')\n",
    "plt.xlim(2,6)\n",
    "plt.ylabel('Mels')\n",
    "plt.title('Fearful')\n",
    "plt.tight_layout()\n",
    "\n",
    "melspectrogram = librosa.feature.melspectrogram(y=disgust_waveform, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "plt.subplot(2, 4, 7)\n",
    "librosa.display.specshow(librosa.power_to_db(S=melspectrogram, ref=np.mean),y_axis='mel',fmax=8000, x_axis='time', norm=Normalize(vmin=-20,vmax=20))\n",
    "#plt.colorbar(format='%+2.0f dB',label='Amplitude')\n",
    "plt.xlim(2,6)\n",
    "plt.ylabel('Mels')\n",
    "plt.title('Disgust')\n",
    "\n",
    "melspectrogram = librosa.feature.melspectrogram(y=surprised_waveform, sr=sample_rate, n_mels=128, fmax=8000)\n",
    "plt.subplot(2, 4, 8)\n",
    "librosa.display.specshow(librosa.power_to_db(S=melspectrogram, ref=np.mean),y_axis='mel',fmax=8000, x_axis='time', norm=Normalize(vmin=-20,vmax=20))\n",
    "plt.colorbar(format='%+2.0f dB',label='Amplitude')\n",
    "plt.xlim(2,6)\n",
    "plt.ylabel('Mels')\n",
    "plt.title('Surprised')\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Mel spectrogram of audio files in the RAV emotion dataset', fontsize=36, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model constructions using SVM and MLP algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Loading dataset and getting description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Openning the dataset\n",
    "data = pd.read_csv('RAV_extracted_features.csv')\n",
    "## Disgust and surprised emoptions will be dropped as these emotions are only present in the speech channel.\n",
    "data.drop(data[data['emotions'] == \"disgust\"].index, inplace = True)\n",
    "data.drop(data[data['emotions'] == \"surprised\"].index, inplace = True)\n",
    "# Description of dataset to check distribution\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Defining predictors and tagte variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the data to avoid over/under representation of one class in the training/test dataset\n",
    "data = data.sample(frac=1)\n",
    "\n",
    "# Features and target columns\n",
    "X = data.drop(['emotions', 'gender'], axis = 1).values\n",
    "y = data['emotions'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "FEi7oYozW0_L",
    "outputId": "9e6b2a57-af09-4185-f640-0dd846f75ca5"
   },
   "source": [
    "#### 5.3 Predictor scaling using two alternative approaches\n",
    "\n",
    "Examination of data showed significant variations in data distribution. It was therefore decided to scale the data. Initially, the predictors and the target variable (emotions) were defined. From the sklearn library, the train_test_split function was used to split predictors and target into 80 and 20% for train and test subsets, respectively. Subsequently, to identify the most appropriate scaling approach, two available scaling methods within the sklearn library were used. StandardScaler (standard) achieves scaling by producing predictors with mean zero and scaling data to unit variance, that is, variance and standard deviation of 1. Min-Max scaling will transform predictors into a range between [0, 1] or [-1, 1]. Furthermore, the target multiclass variable (emotions) was in categorical form, therefore encoded using LabelEncoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=42, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encoding multiclass categorical y\n",
    "y_train=LabelEncoder().fit_transform(y_train)\n",
    "y_test=LabelEncoder().fit_transform(y_test)\n",
    "\n",
    "## Standard scaling\n",
    "scaler1 = MinMaxScaler()\n",
    "X_train_minmax = X_train\n",
    "X_test_minmax = X_test\n",
    "X_train_minmax = scaler1.fit_transform(X_train_minmax)\n",
    "X_test_minmax = scaler1.fit_transform(X_test_minmax)\n",
    "\n",
    "# Min-Max scaling\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test \n",
    "X_train_scaled = scaler2.fit_transform(X_train_scaled)\n",
    "X_test_scaled = scaler2.fit_transform(X_test_scaled)\n",
    "\n",
    "# Print scaled dataset to check whether they have been scaled\n",
    "X_train_minmax_df = pd.DataFrame(X_train_minmax)\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled)\n",
    "\n",
    "\n",
    "# print some details\n",
    "# number of samples in training data\n",
    "print(\"[+] Number of unscaled training samples:\", X_train.shape[0])\n",
    "print(\"[+] Number of scaled training samples:\", X_train_scaled.shape[0])\n",
    "print(\"[+] Number of minmax scaled training samples:\", X_train_minmax.shape[0])\n",
    "\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of unscaled testing samples:\", X_test.shape[0])\n",
    "print(\"[+] Number of scaled testing samples:\", X_test_scaled.shape[0])\n",
    "print(\"[+] Number of minmax scaled testing samples:\", X_test_minmax.shape[0])\n",
    "\n",
    "# Get the number of features extracted\n",
    "print(f'Features extracted for unscaled: {X_train.shape[1]}')\n",
    "print(f'Features extracted for scaled: {X_train_scaled.shape[1]}')\n",
    "print(f'Features extracted for minmax scaled: {X_train_minmax.shape[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 The SVM algorithm for emotion classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1 SVM model using unscaled data and default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SVC()\n",
    "\n",
    "model1.fit(X_train, y_train)\n",
    "model1.score(X_test, y_test)\n",
    "\n",
    "print(f'SVC Model\\'s accuracy on training set is {100*model1.score(X_train, y_train):.2f}%')\n",
    "print(f'SVC Model\\'s accuracy on test set is {100*model1.score(X_test, y_test):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(2, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    ClassificationReport(model1, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    ClassPredictionError(model1, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    PrecisionRecallCurve(model1, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ROCAUC(model1, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train, y_train)\n",
    "    viz.score(X_test, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of SVC classifier with default parameters using non-scaled dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model1.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2 SVM model using min-max scaled data and default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SVC()\n",
    "\n",
    "model2.fit(X_train_minmax, y_train)\n",
    "model2.score(X_test_minmax, y_test)\n",
    "\n",
    "print(f'SVC Model\\'s accuracy on training set is {100*model2.score(X_train_minmax, y_train):.2f}%')\n",
    "print(f'SVC Model\\'s accuracy on test set is {100*model2.score(X_test_minmax, y_test):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(2, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    ClassificationReport(model2, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    ClassPredictionError(model2, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    PrecisionRecallCurve(model2, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ROCAUC(model2, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_minmax, y_train)\n",
    "    viz.score(X_test_minmax, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of SVM classifier with default parameters on min-max scaled dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model2.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3 SVM model using standard scaled data and default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = SVC()\n",
    "\n",
    "model3.fit(X_train_scaled, y_train)\n",
    "model3.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f'SVC Model\\'s accuracy on training set is {100*model3.score(X_train_scaled, y_train):.2f}%')\n",
    "print(f'SVC Model\\'s accuracy on test set is {100*model3.score(X_test_scaled, y_test):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(2, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    ClassificationReport(model3, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    ClassPredictionError(model3, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    PrecisionRecallCurve(model3, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ROCAUC(model3, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled, y_train)\n",
    "    viz.score(X_test_scaled, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of SVM classifier with default parameters on standard scaled dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model3.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.4 Grid search to find optimal SVM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################# Do not run ############################################################################\n",
    "# RANDOM SEARCH FOR 20 COMBINATIONS OF PARAMETERS\n",
    "\n",
    "tic = time.perf_counter()\n",
    "k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "param_grid1 = {'kernel': ['rbf', 'poly', 'linear'],\n",
    "            \"C\": stats.uniform(2, 50),\n",
    "            \"gamma\": stats.uniform(0.01, 1)}\n",
    "              \n",
    "grid1 = RandomizedSearchCV(SVC(), param_distributions = param_grid1, n_iter = 20, n_jobs = -1, cv = k, scoring = \"accuracy\") \n",
    "grid1.fit(X_train_scaled, y_train)\n",
    "\n",
    "#print(grid1.cv_results_)\n",
    "print(grid1.best_params_)\n",
    "print(grid1.score(X_test_scaled, y_test))\n",
    "print()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to run the RandomizedSearchCV for SVC is {toc - tic:0.4f} seconds\")\n",
    "print()\n",
    "\n",
    "dump(grid1.best_estimator_, 'SVM_best_estimator_grid1.joblib', compress = 1) # Saving the best estimators\n",
    "dump(grid1.cv_results_, 'SVM_CV_result_grid1.pkl')                           # Saving the whole object\n",
    "dump(grid1, 'SVM_whole_object_grid1.pkl')                                    # Saving the whole object\n",
    "\n",
    "#### Visualisation of the search performance\n",
    "df_grid1 = load('SVM_CV_result_grid1.pkl')\n",
    "df_grid1 = pd.DataFrame(df_grid1)\n",
    "# Create a 3d scatter plot of the data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x_points = df_grid1['param_gamma']\n",
    "y_points = df_grid1['mean_score_time']\n",
    "z_points = df_grid1['mean_test_score']\n",
    "colour = df_grid1['rank_test_score']\n",
    "sctt = ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='jet');\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Mean score time')\n",
    "ax.set_zlabel('Score')\n",
    "fig.colorbar(sctt, shrink=0.5)\n",
    "ax.view_init(elev=15, azim=30)\n",
    "ax.text2D(0, 1, \"3D visualisation of SVC Grid1 randomized SearchCV performance\", transform=ax.transAxes)\n",
    "fig.savefig(\"grid1_3d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.5 SVM with suggested optimal hyperparameters from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = SVC(\n",
    "    C = 41.80717878639727,\n",
    "    gamma = 0.03079471598867322,\n",
    "    kernel = 'rbf',\n",
    "    random_state = 69\n",
    ")\n",
    "\n",
    "model4.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'SVC Model\\'s accuracy on training set is {100*model4.score(X_train_scaled, y_train):.2f}%')\n",
    "print(f'SVC Model\\'s accuracy on test set is {100*model4.score(X_test_scaled, y_test):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model4, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model4, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model4, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model4, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled, y_train)\n",
    "    viz.score(X_test_scaled, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of SVM classifier with optimal parameters on standard scaled dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model4.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.6 Confusion matrix of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.style import set_palette\n",
    "sns.set_context('paper', font_scale=2)\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(25, 12))\n",
    "viz = ConfusionMatrix(model1, support=True,  cmap='GnBu', title=\"SVM classification on unscaled data\", ax=ax1)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model2, support=True, cmap='GnBu', title=\"SVM classification on min-max data\", ax=ax2)\n",
    "viz.fit(X_train_minmax, y_train)\n",
    "viz.score(X_test_minmax, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model3, support=True, cmap='GnBu', title=\"SVM classification on standard scaled data\", ax=ax3)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model4, support=True, cmap='GnBu', title=\"Optimised SVM classification on standard scaled data\", ax=ax4)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "f.suptitle('Confusion matrix of 4 SVM models on unscaled, min-max and standard scaled and after optimisation on standard scaled', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "f.savefig(\"Confusion_matrix1_SVC.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 The MLP Model for Emotion Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.1 MLP model using non-scaled data and default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP classifier with default parameter\n",
    "model5 = MLPClassifier()\n",
    "\n",
    "model5.fit(X_train, y_train)\n",
    "pred_y = model5.predict(X_test)\n",
    "\n",
    "print(f'MLP Model\\'s accuracy on training set is {100*model5.score(X_train, y_train):.2f}%')\n",
    "print(f'MLP Model\\'s accuracy on test set is {100*model5.score(X_test, y_test):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(2, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    ClassificationReport(model5, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    ClassPredictionError(model5, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    PrecisionRecallCurve(model5, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ROCAUC(model5, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train, y_train)\n",
    "    viz.score(X_test, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of MLP classifier with default parameters on non-scaled dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model5.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.2 MLP model using min-max scaled data and default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP classifier with default parameter\n",
    "model6 = MLPClassifier()\n",
    "\n",
    "model6.fit(X_train_minmax, y_train)\n",
    "pred_y = model6.predict(X_test_minmax)\n",
    "\n",
    "print(f'MLP Model\\'s accuracy on training set is {100*model6.score(X_train_minmax, y_train):.2f}%')\n",
    "print(f'MLP Model\\'s accuracy on test set is {100*model6.score(X_test_minmax, y_test):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(2, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    ClassificationReport(model6, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    ClassPredictionError(model6, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    PrecisionRecallCurve(model6, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ROCAUC(model6, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_minmax, y_train)\n",
    "    viz.score(X_test_minmax, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of MLP classifier with default parameters on min-max scaled dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model6.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.3 MLP model using standard scaled data and default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP classifier with default parameter\n",
    "model7 = MLPClassifier()\n",
    "\n",
    "model7.fit(X_train_scaled, y_train)\n",
    "pred_y = model7.predict(X_test_scaled)\n",
    "\n",
    "print(f'MLP Model\\'s accuracy on training set is {100*model7.score(X_train_scaled, y_train):.2f}%')\n",
    "print(f'MLP Model\\'s accuracy on test set is {100*model7.score(X_test_scaled, y_test):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(2, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    ClassificationReport(model7, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    ClassPredictionError(model7, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    PrecisionRecallCurve(model7, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ROCAUC(model7, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled, y_train)\n",
    "    viz.score(X_test_scaled, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of MLP classifier with default parameters on standard scaled dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model7.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.4 Grid search to find optimal parameters for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################ Do not run ###################################################################\n",
    "# Initialize the MLP Classifier and choose parameters we want to keep constant\n",
    "tic = time.perf_counter()\n",
    "\n",
    "k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "mlp = MLPClassifier(\n",
    "    # tune batch size later \n",
    "    batch_size=256,  \n",
    "    # keep random state constant to accurately compare subsequent models\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Choose the grid of hyperparameters we want to use for Grid Search to build our candidate models\n",
    "param_grid2 = {\n",
    "    'hidden_layer_sizes': [(8,), (180,), (300,),(100,50,),(10,10,10)], \n",
    "    'activation': ['tanh','relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'epsilon': [1e-08, 0.1],\n",
    "    'learning_rate': ['adaptive', 'constant'],\n",
    "}\n",
    "              \n",
    "grid2 = RandomizedSearchCV(mlp, param_distributions = param_grid2, n_iter = 20, n_jobs = -1, cv = k, scoring = \"accuracy\") \n",
    "grid2.fit(X_train_scaled, y_train)\n",
    "\n",
    "#print(grid2.cv_results_)\n",
    "print(grid2.best_params_)\n",
    "print(grid2.score(X_test_scaled, y_test))\n",
    "print()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to run the RandomizedSearchCV for SVC is {toc - tic:0.4f} seconds\")\n",
    "print()\n",
    "\n",
    "dump(grid2.best_estimator_, 'MLP_best_estimator_grid2.joblib', compress = 1) # Saving the best estimators\n",
    "dump(grid2.cv_results_, 'MLP_CV_result_grid2.pkl')                           # Saving the whole object\n",
    "dump(grid2, 'MLP_whole_object_grid2.pkl')                                    # Saving the whole object\n",
    "\n",
    "### Visualisation of search performance\n",
    "df_grid2 = load('MLP_CV_result_grid2.pkl')\n",
    "df_grid2 = pd.DataFrame(df_grid2)\n",
    "# Create a 3d scatter plot of the data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x_points = df_grid2['param_alpha']\n",
    "y_points = df_grid2['mean_score_time']\n",
    "z_points = df_grid2['mean_test_score']\n",
    "colour = df_grid2['rank_test_score']\n",
    "sctt = ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='jet');\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Mean score time')\n",
    "ax.set_zlabel('Score')\n",
    "fig.colorbar(sctt, shrink=0.5)\n",
    "ax.view_init(elev=15, azim=30)\n",
    "ax.text2D(0, 1, \"3D visualisation of MLP Grid2 randomized SearchCV performance\", transform=ax.transAxes)\n",
    "fig.savefig(\"grid2_3d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.5 MLP with suggested optimal hyperparameters from the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP classifer with best parameters from the grid search with the scaled data\n",
    "\n",
    "model8 = MLPClassifier(\n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    alpha=0.001, \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    batch_size=256, \n",
    "    epsilon=1e-08, \n",
    "    hidden_layer_sizes=(100, 50), \n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    early_stopping=False, # without early stopping\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "model8.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'MLP Model\\'s accuracy on training set is {100*model8.score(X_train_scaled, y_train):.2f}%')\n",
    "print(f'MLP Model\\'s accuracy on test set is {100*model8.score(X_test_scaled, y_test):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model8, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model8, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model8, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model8, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model8, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model8, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled, y_train)\n",
    "    viz.score(X_test_scaled, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of MLP classifier with optimal parameters on standard scaled dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model8.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.6 MLP with suggested optimal hyperparameters and early stopping to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP classifer with best parameters from the grid search with the scaled data\n",
    "\n",
    "model9 = MLPClassifier(\n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    alpha=0.001, \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    batch_size=256, \n",
    "    epsilon=1e-08, \n",
    "    hidden_layer_sizes=(100, 50), \n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    early_stopping=True, # without early stopping\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "model9.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f'MLP Model\\'s accuracy on training set is {100*model9.score(X_train_scaled, y_train):.2f}%')\n",
    "print(f'MLP Model\\'s accuracy on test set is {100*model9.score(X_test_scaled, y_test):.2f}%')\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model9, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model9, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model9, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model9, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model9, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model9, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled, y_train)\n",
    "    viz.score(X_test_scaled, y_test)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of optimised MLP classifier with early stopping to avoid overfitting', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model9.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.7 Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.style import set_palette\n",
    "set_palette('paired')\n",
    "f, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(25, 12))\n",
    "viz = ConfusionMatrix(model5, support=True, cmap='GnBu', title=\"MLP classification on unscaled data\", ax=ax1)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model6, support=True, cmap='GnBu', title=\"MLP classification on min-max data\", ax=ax2)\n",
    "viz.fit(X_train_minmax, y_train)\n",
    "viz.score(X_test_minmax, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model7, support=True, cmap='GnBu', title=\"MLP classification on standard scaled data\", ax=ax3)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model8, support=True, cmap='GnBu', title=\"Optimised MLP classification on standard scaled data\", ax=ax4)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model9, support=True, cmap='GnBu', title=\"Optimised MLP classification on standard scaled data with early stopping\", ax=ax5)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "f.suptitle('Confusion matrix of 5 MLP models on unscaled, min-max, standard scaled and optimised standard scaled with/without early stopping', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "f.savefig(\"Confusion_matrix2_MLP.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.8 Comparison of best (optimised) SVM and MLP models (model 4 and 9) on standard scaled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=2)\n",
    "f, ((ax1, ax2, ax3,), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(25, 12))\n",
    "set_palette('paired')\n",
    "viz = ClassificationReport(model4, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"SVM classification report using standard scaled data\", ax=ax1)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "viz = ClassPredictionError(model4, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"SVM prediction error using standard scaled data\", ax=ax2)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model4, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"SVM confusion matrix using standard scaled data\", ax=ax3)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "viz = ClassificationReport(model8, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"MLP classification report using standard scaled data\", ax=ax4)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "viz = ClassPredictionError(model8, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"MLP prediction error using standard scaled data\", ax=ax5)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model8, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"MLP confusion matrix using standard scaled data\", ax=ax6)\n",
    "viz.fit(X_train_scaled, y_train)\n",
    "viz.score(X_test_scaled, y_test)\n",
    "viz.finalize()\n",
    "f.suptitle('Comparative performance of optimised SVM and MLP classification using standard scaled data', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "f.savefig(\"Comparative_performance1.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data augmentation and addressing data imbalance using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Audio file augmentation and extraction of predictors from these audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data augmentation using pydiogment library. Here two sets of additional files created by changing the original .wav files through two process of \"fade in and out\"\n",
    "# and \"change tone\"\n",
    "for file in glob.glob('..\\\\data\\\\RAV\\\\Actor_*\\\\*.wav'):\n",
    "    fade_in_and_out(file)\n",
    "    change_tone(file, 1.1)\n",
    "\n",
    "### Iterating through augmented datset for predictor eaxtraction    \n",
    "augmented_data = load_data()\n",
    "\n",
    "X_augmented = pd.DataFrame(augmented_data[\"X\"])\n",
    "channel_augmented = pd.DataFrame(augmented_data[\"channel\"],columns=['channel'])\n",
    "gender_augmented = pd.DataFrame(augmented_data[\"gender\"],columns=['gender']) \n",
    "y_augmented = pd.DataFrame(augmented_data[\"y\"],columns=['emotions'])\n",
    "\n",
    "# print some details\n",
    "# number of samples in training data\n",
    "print(\"[+] Number of training samples:\", X_augmented.shape[0])\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of testing samples:\", y_augmented.shape[0])\n",
    "# Get the number of features extracted\n",
    "print(f'Features extracted: {X_augmented.shape[1]}')\n",
    "\n",
    "### Saving the augmented dataset\n",
    "data_augmented = pd.concat([X_augmented, channel_augmented, gender_augmented, y_augmented], axis =1)\n",
    "data_augmented.to_csv(\"RAV_extracted_features_augmented.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Loading augmented dataset, predictor and target definition, SMOTE and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Openning the saved augmented dataset\n",
    "data_augmented = pd.read_csv('RAV_extracted_features_augmented.csv')\n",
    "data_augmented.drop(data_augmented[data_augmented['emotions'] == \"disgust\"].index, inplace = True)\n",
    "data_augmented.drop(data_augmented[data_augmented['emotions'] == \"surprised\"].index, inplace = True)\n",
    "\n",
    "# shuffling the data to avoid over/under representation of one class in the training/test dataset\n",
    "data_augmented = data_augmented.sample(frac=1)\n",
    "\n",
    "# Features and target columns\n",
    "X_augmented = data_augmented.drop(['emotions', 'gender'], axis = 1).values\n",
    "y_augmented = data_augmented['emotions'].values\n",
    "oversample = SMOTE()\n",
    "X_augmented, y_augmented = oversample.fit_resample(X_augmented, y_augmented)\n",
    "\n",
    "# Split the dataset unscaled\n",
    "X_train_augmented, X_test_augmented, y_train_augmented, y_test_augmented= train_test_split(X_augmented, y_augmented, random_state=42, test_size=0.20)\n",
    "\n",
    "### Encoding the target labels\n",
    "## Encoding multiclass categorical y\n",
    "y_train_augmented=LabelEncoder().fit_transform(y_train_augmented)\n",
    "y_test_augmented=LabelEncoder().fit_transform(y_test_augmented)\n",
    "\n",
    "# Min-Max scaling\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled_augmented = X_train_augmented\n",
    "X_test_scaled_augmented = X_test_augmented \n",
    "X_train_scaled_augmented = scaler2.fit_transform(X_train_scaled_augmented)\n",
    "X_test_scaled_augmented = scaler2.fit_transform(X_test_scaled_augmented)\n",
    "\n",
    "# Print scaled dataset to check whether they have been scaled\n",
    "X_train_scaled_augmented_df = pd.DataFrame(X_train_scaled_augmented)\n",
    "\n",
    "\n",
    "# print some details\n",
    "# number of samples in training data\n",
    "print(\"[+] Number of unscaled training samples:\", X_train_augmented.shape[0])\n",
    "print(\"[+] Number of scaled training samples:\", X_train_scaled_augmented.shape[0])\n",
    "\n",
    "# number of samples in testing data\n",
    "print(\"[+] Number of unscaled testing samples:\", X_test_augmented.shape[0])\n",
    "print(\"[+] Number of scaled testing samples:\", X_test_scaled_augmented.shape[0])\n",
    "\n",
    "# Get the number of features extracted\n",
    "print(f'Features extracted for unscaled: {X_train_augmented.shape[1]}')\n",
    "print(f'Features extracted for scaled: {X_train_scaled_augmented.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 RandomizedSearchCV to tune SVM parameters using the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################# Do not run ######################################################################\n",
    "tic = time.perf_counter()\n",
    "k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "\n",
    "param_grid3 = {'kernel': ['rbf', 'poly', 'linear'],\n",
    "            \"C\": stats.uniform(2, 50),\n",
    "            \"gamma\": stats.uniform(0.01, 1)}\n",
    "              \n",
    "grid3 = RandomizedSearchCV(SVC(), param_distributions = param_grid3, n_iter = 20, n_jobs = -1, cv = k, scoring = \"accuracy\") \n",
    "grid3.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "\n",
    "#print(grid1.cv_results_)\n",
    "print(grid3.best_params_)\n",
    "print(grid3.score(X_test_scaled_augmented, y_test_augmented))\n",
    "print()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to run the RandomizedSearchCV for SVC is {toc - tic:0.4f} seconds\")\n",
    "print()\n",
    "\n",
    "dump(grid3.best_estimator_, 'SVM_best_estimator_augmented_grid3.joblib', compress = 1) # Saving the best estimators\n",
    "dump(grid3.cv_results_, 'SVM_CV_result_grid3.pkl')                           # Saving the whole object\n",
    "dump(grid3, 'SVM_whole_object_augmented_grid3.pkl')                          # Saving the whole object\n",
    "\n",
    "### 3D visualisation of search performance\n",
    "df_grid3 = load('SVM_CV_result_grid3.pkl')\n",
    "df_grid3 = pd.DataFrame(df_grid3)\n",
    "# Create a 3d scatter plot of the data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x_points = df_grid3['param_gamma']\n",
    "y_points = df_grid3['mean_score_time']\n",
    "z_points = df_grid3['mean_test_score']\n",
    "colour = df_grid3['rank_test_score']\n",
    "sctt = ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='jet');\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Mean score time')\n",
    "ax.set_zlabel('Score')\n",
    "fig.colorbar(sctt, shrink=0.5)\n",
    "ax.view_init(elev=15, azim=30)\n",
    "ax.text2D(0, 1, \"3D visualisation of SVM grid3 randomized SearchCV performance on the augmented data\", transform=ax.transAxes)\n",
    "fig.savefig(\"grid3_3d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Performing SVM classification on augmented data using optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = SVC(\n",
    "    C = 44.98800565318603,\n",
    "    gamma = 0.1554129361088037,\n",
    "    kernel = 'poly',\n",
    "    random_state = 69\n",
    ")\n",
    "\n",
    "model10.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "\n",
    "print(f'SVC Model\\'s accuracy on training set is {100*model10.score(X_train_scaled_augmented, y_train_augmented):.2f}%')\n",
    "print(f'SVC Model\\'s accuracy on test set is {100*model10.score(X_test_scaled_augmented, y_test_augmented):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model10, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model10, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model10, cmap='GnBu', support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model10, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model10, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model10, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "    viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of optimised SVM classifier on augmented dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model10.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 RandomizedSearchCV to tune MLP parameters using the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################ Do not run ###################################################################\n",
    "# Initialize the MLP Classifier and choose parameters we want to keep constant\n",
    "tic = time.perf_counter()\n",
    "\n",
    "k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "mlp = MLPClassifier(\n",
    "    # tune batch size later \n",
    "    batch_size=256,  \n",
    "    # keep random state constant to accurately compare subsequent models\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Choose the grid of hyperparameters we want to use for Grid Search to build our candidate models\n",
    "param_grid4 = {\n",
    "    'hidden_layer_sizes': [(8,), (180,), (300,),(100,50,),(10,10,10)], \n",
    "    'activation': ['tanh','relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'epsilon': [1e-08, 0.1],\n",
    "    'learning_rate': ['adaptive', 'constant'],\n",
    "}\n",
    "              \n",
    "grid4 = RandomizedSearchCV(mlp, param_distributions = param_grid4, n_iter = 20, n_jobs = -1, cv = k, scoring = \"accuracy\") \n",
    "grid4.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "\n",
    "#print(grid4.cv_results_)\n",
    "print(grid4.best_params_)\n",
    "print(grid4.score(X_test_scaled_augmented, y_test_augmented))\n",
    "print()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to run the RandomizedSearchCV for SVC is {toc - tic:0.4f} seconds\")\n",
    "print()\n",
    "\n",
    "dump(grid4.best_estimator_, 'MLP_best_estimator_grid4.joblib', compress = 1) # Saving the best estimators\n",
    "dump(grid4.cv_results_, 'MLP_CV_result_grid4.pkl')                           # Saving the whole object\n",
    "dump(grid4, 'MLP_whole_object_grid4.pkl')                                    # Saving the whole object\n",
    "\n",
    "### 3D visualisation of search performance\n",
    "df_grid4 = load('MLP_CV_result_grid4.pkl')\n",
    "df_grid4 = pd.DataFrame(df_grid4)\n",
    "# Create a 3d scatter plot of the data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x_points = df_grid4['param_alpha']\n",
    "y_points = df_grid4['mean_score_time']\n",
    "z_points = df_grid4['mean_test_score']\n",
    "colour = df_grid4['rank_test_score']\n",
    "sctt = ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='jet');\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Mean score time')\n",
    "ax.set_zlabel('Score')\n",
    "fig.colorbar(sctt, shrink=0.5)\n",
    "ax.view_init(elev=15, azim=30)\n",
    "ax.text2D(0, 1, \"3D visualisation of MLP Grid2 randomized SearchCV performance on the augmented data\", transform=ax.transAxes)\n",
    "fig.savefig(\"grid4_3d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.6 Performing MLP classification on augmented data using optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP classifer with best parameters from the grid search with the scaled data\n",
    "\n",
    "model11 = MLPClassifier(\n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    alpha=0.0001, \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    batch_size=256, \n",
    "    epsilon=1e-08, \n",
    "    hidden_layer_sizes=(300,), \n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    early_stopping=True, # without early stopping\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "model11.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "\n",
    "print(f'MLP Model\\'s accuracy on training set is {100*model11.score(X_train_scaled_augmented, y_train_augmented):.2f}%')\n",
    "print(f'MLP Model\\'s accuracy on test set is {100*model11.score(X_test_scaled_augmented, y_test_augmented):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model11, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model11, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model11, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model11, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model11, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model11, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "    viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of optimised MLP classifier on augmented dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model11.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7 Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2, figsize=(25, 12))\n",
    "set_aesthetic(palette='dark', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "classes=['neutral','calm','happy', 'sad','angry','fearful']\n",
    "visualgrid = [\n",
    "    ConfusionMatrix(model10, classes=classes, cmap='GnBu', title=\"Optimised SVM classification on augmented data\", ax=ax1),\n",
    "    ConfusionMatrix(model11, classes=classes, cmap='GnBu', title=\"Optimised MLP classification on augmented data\", ax=ax2),\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "    viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "    viz.finalize()\n",
    "f.suptitle('Confusion matrix for optimised SVM and MLP models on augmented data', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "f.savefig(\"Confusion_matrix3_MLP_SVM_augmented.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.8 Comparative performance of optimised SVM and MLP classification (model 10 and 11) on augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=2)\n",
    "set_palette('paired')\n",
    "f, ((ax1, ax2, ax3,), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(25, 12))\n",
    "viz = ClassificationReport(model10, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"SVM classification report using augmented data\", ax=ax1)\n",
    "viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "viz.finalize()\n",
    "viz = ClassPredictionError(model10, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"SVM prediction error using augmented data\", ax=ax2)\n",
    "viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model10, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"SVM confusion matrix using augmented data\", ax=ax3)\n",
    "viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "viz.finalize()\n",
    "viz = ClassificationReport(model11, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"MLP classification report using augmented data\", ax=ax4)\n",
    "viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "viz.finalize()\n",
    "viz = ClassPredictionError(model11, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"MLP prediction error using augmented data\", ax=ax5)\n",
    "viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model11, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"MLP confusion matrix using augmented data\", ax=ax6)\n",
    "viz.fit(X_train_scaled_augmented, y_train_augmented)\n",
    "viz.score(X_test_scaled_augmented, y_test_augmented)\n",
    "viz.finalize()\n",
    "f.suptitle('Comparative performance of optimised SVM amd MLP classification using augmented data', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "f.savefig(\"Comparative_performance2.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Spliting the dataset based on channel (speech and song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target columns\n",
    "data_augmented = pd.read_csv('RAV_extracted_features_augmented.csv')\n",
    "speech_data_augmented = data_augmented.loc[data_augmented['channel'] == 1]\n",
    "song_data_augmented = data_augmented.loc[data_augmented['channel'] == 2]\n",
    "\n",
    "speech_data_augmented.drop(speech_data_augmented[speech_data_augmented['emotions'] == \"disgust\"].index, inplace = True)\n",
    "speech_data_augmented.drop(speech_data_augmented[speech_data_augmented['emotions'] == \"surprised\"].index, inplace = True)\n",
    "\n",
    "song_data_augmented.drop(song_data_augmented[song_data_augmented['emotions'] == \"disgust\"].index, inplace = True)\n",
    "song_data_augmented.drop(song_data_augmented[song_data_augmented['emotions'] == \"surprised\"].index, inplace = True)\n",
    "\n",
    "### Speech\n",
    "X_augmented_speech = speech_data_augmented.drop(['emotions', 'gender', 'channel'], axis = 1).values\n",
    "y_augmented_speech = speech_data_augmented['emotions'].values\n",
    "oversample = SMOTE()\n",
    "X_augmented_speech, y_augmented_speech = oversample.fit_resample(X_augmented_speech, y_augmented_speech)\n",
    "\n",
    "# Split the dataset unscaled\n",
    "X_train_augmented_speech, X_test_augmented_speech, y_train_augmented_speech, y_test_augmented_speech= train_test_split(X_augmented_speech, y_augmented_speech, random_state=42, test_size=0.20)\n",
    "## y label encoding\n",
    "y_train_augmented_speech=LabelEncoder().fit_transform(y_train_augmented_speech)\n",
    "y_test_augmented_speech=LabelEncoder().fit_transform(y_test_augmented_speech)\n",
    "# Standard scaling\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled_augmented_speech = X_train_augmented_speech\n",
    "X_test_scaled_augmented_speech = X_test_augmented_speech \n",
    "X_train_scaled_augmented_speech = scaler2.fit_transform(X_train_scaled_augmented_speech)\n",
    "X_test_scaled_augmented_speech = scaler2.fit_transform(X_test_scaled_augmented_speech)\n",
    "\n",
    "### song\n",
    "X_augmented_song = song_data_augmented.drop(['emotions', 'gender', 'channel'], axis = 1).values\n",
    "y_augmented_song = song_data_augmented['emotions'].values\n",
    "X_augmented_song, y_augmented_song = oversample.fit_resample(X_augmented_song, y_augmented_song)\n",
    "# Split the dataset unscaled\n",
    "X_train_augmented_song, X_test_augmented_song, y_train_augmented_song, y_test_augmented_song= train_test_split(X_augmented_song, y_augmented_song, random_state=42, test_size=0.20)\n",
    "## y label encoding\n",
    "y_train_augmented_song=LabelEncoder().fit_transform(y_train_augmented_song)\n",
    "y_test_augmented_song=LabelEncoder().fit_transform(y_test_augmented_song)\n",
    "# Standard scaling\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled_augmented_song = X_train_augmented_song\n",
    "X_test_scaled_augmented_song = X_test_augmented_song \n",
    "X_train_scaled_augmented_song = scaler2.fit_transform(X_train_scaled_augmented_song)\n",
    "X_test_scaled_augmented_song = scaler2.fit_transform(X_test_scaled_augmented_song)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 RandomizedSearchCV to tune SVM parameters using the speech channel of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################# Do not run ######################################################################\n",
    "tic = time.perf_counter()\n",
    "k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "\n",
    "param_grid5 = {'kernel': ['rbf', 'poly', 'linear'],\n",
    "            \"C\": stats.uniform(2, 50),\n",
    "            \"gamma\": stats.uniform(0.01, 1)}\n",
    "              \n",
    "grid5 = RandomizedSearchCV(SVC(), param_distributions = param_grid5, n_iter = 20, n_jobs = -1, cv = k, scoring = \"accuracy\") \n",
    "grid5.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "\n",
    "#print(grid1.cv_results_)\n",
    "print(grid5.best_params_)\n",
    "print(grid5.score(X_test_scaled_augmented_speech, y_test_augmented_speech))\n",
    "print()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to run the RandomizedSearchCV for SVC is {toc - tic:0.4f} seconds\")\n",
    "print()\n",
    "\n",
    "dump(grid5.best_estimator_, 'SVM_best_estimator_augmented_speech_grid5.joblib', compress = 1) # Saving the best estimators\n",
    "dump(grid5.cv_results_, 'SVM_CV_result_augmented_speech_grid5.pkl')                           # Saving the whole object\n",
    "dump(grid5, 'SVM_whole_object_augmented_speech_grid5.pkl')                                    # Saving the whole object\n",
    "\n",
    "## 3D visualisation of search performance\n",
    "df_grid5 = load('SVM_CV_result_augmented_speech_grid5.pkl')\n",
    "df_grid5 = pd.DataFrame(df_grid5)\n",
    "# Create a 3d scatter plot of the data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x_points = df_grid5['param_gamma']\n",
    "y_points = df_grid5['mean_score_time']\n",
    "z_points = df_grid5['mean_test_score']\n",
    "colour = df_grid5['rank_test_score']\n",
    "sctt = ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='jet');\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Mean score time')\n",
    "ax.set_zlabel('Score')\n",
    "fig.colorbar(sctt, shrink=0.5)\n",
    "ax.view_init(elev=15, azim=30)\n",
    "ax.text2D(0, 1, \"3D visualisation of SVM Grid5 randomized SearchCV performance on the speech channel of augmented data\", transform=ax.transAxes)\n",
    "fig.savefig(\"grid5_3d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 SVM classification using optimal parameters on speech channel of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12 = SVC(\n",
    "    C = 39.41309679301661,\n",
    "    gamma = 0.060427225273544265,\n",
    "    kernel = 'poly',\n",
    "    random_state = 69\n",
    ")\n",
    "\n",
    "model12.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "\n",
    "print(f'SVC Model\\'s accuracy on training set is {100*model12.score(X_train_scaled_augmented_speech, y_train_augmented_speech):.2f}%')\n",
    "print(f'SVC Model\\'s accuracy on test set is {100*model12.score(X_test_scaled_augmented_speech, y_test_augmented_speech):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model12, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model12, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model12, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model12, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model12, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model12, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "    viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of optimised SVM classifier with optimal parameters on speech channel', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model12.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 RandomizedSearchCV to tune SVM parameters using the song channel of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################# Do not run ######################################################################\n",
    "tic = time.perf_counter()\n",
    "k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "\n",
    "param_grid6 = {'kernel': ['rbf', 'poly', 'linear'],\n",
    "            \"C\": stats.uniform(2, 50),\n",
    "            \"gamma\": stats.uniform(0.01, 1)}\n",
    "              \n",
    "grid6 = RandomizedSearchCV(SVC(), param_distributions = param_grid6, n_iter = 20, n_jobs = -1, cv = k, scoring = \"accuracy\") \n",
    "grid6.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "\n",
    "#print(grid1.cv_results_)\n",
    "print(grid6.best_params_)\n",
    "print(grid6.score(X_test_scaled_augmented_song, y_test_augmented_song))\n",
    "print()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to run the RandomizedSearchCV for SVC is {toc - tic:0.4f} seconds\")\n",
    "print()\n",
    "\n",
    "dump(grid6.best_estimator_, 'SVM_best_estimator_augmented_song_grid6.joblib', compress = 1) # Saving the best estimators\n",
    "dump(grid6.cv_results_, 'SVM_CV_result_augmented_song_grid6.pkl')                           # Saving the whole object\n",
    "dump(grid6, 'SVM_whole_object_augmented_song_grid6.pkl')                                    # Saving the whole object\n",
    "\n",
    "### 3D visualisation of search performance\n",
    "df_grid6 = load('SVM_CV_result_augmented_song_grid6.pkl')\n",
    "df_grid6 = pd.DataFrame(df_grid6)\n",
    "# Create a 3d scatter plot of the data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x_points = df_grid6['param_gamma']\n",
    "y_points = df_grid6['mean_score_time']\n",
    "z_points = df_grid6['mean_test_score']\n",
    "colour = df_grid6['rank_test_score']\n",
    "sctt = ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='jet');\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Mean score time')\n",
    "ax.set_zlabel('Score')\n",
    "fig.colorbar(sctt, shrink=0.5)\n",
    "ax.view_init(elev=15, azim=30)\n",
    "ax.text2D(0, 1, \"3D visualisation of SVM Grid6 randomized SearchCV performance on the song data\", transform=ax.transAxes)\n",
    "fig.savefig(\"grid6_3d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Performing SVM classification using optimal parameters on song channel of augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model13 = SVC(\n",
    "    C = 49.69210418127462,\n",
    "    gamma = 0.7632177027607225,\n",
    "    kernel = 'poly',\n",
    "    random_state = 69\n",
    ")\n",
    "\n",
    "model13.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "\n",
    "print(f'SVC Model\\'s accuracy on training set is {100*model13.score(X_train_scaled_augmented_song, y_train_augmented_song):.2f}%')\n",
    "print(f'SVC Model\\'s accuracy on test set is {100*model13.score(X_test_scaled_augmented_song, y_test_augmented_song):.2f}%')\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model13, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model13, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model13, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model13, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model13, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model13, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "    viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of optimised SVM classifier with optimal parameters on song channel', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model13.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 RandomizedSearchCV to tune MLP parameters using the speech channel of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################ Do not run ###################################################################\n",
    "# Initialize the MLP Classifier and choose parameters we want to keep constant\n",
    "tic = time.perf_counter()\n",
    "\n",
    "k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "mlp = MLPClassifier(\n",
    "    # tune batch size later \n",
    "    batch_size=256,  \n",
    "    # keep random state constant to accurately compare subsequent models\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Choose the grid of hyperparameters we want to use for Grid Search to build our candidate models\n",
    "param_grid7 = {\n",
    "    'hidden_layer_sizes': [(8,), (180,), (300,),(100,50,),(10,10,10)], \n",
    "    'activation': ['tanh','relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'epsilon': [1e-08, 0.1],\n",
    "    'learning_rate': ['adaptive', 'constant'],\n",
    "}\n",
    "              \n",
    "grid7 = RandomizedSearchCV(mlp, param_distributions = param_grid7, n_iter = 20, n_jobs = -1, cv = k, scoring = \"accuracy\") \n",
    "grid7.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "\n",
    "#print(grid7.cv_results_)\n",
    "print(grid7.best_params_)\n",
    "print(grid7.score(X_test_scaled_augmented_speech, y_test_augmented_speech))\n",
    "print()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to run the RandomizedSearchCV for MLP is {toc - tic:0.4f} seconds\")\n",
    "print()\n",
    "\n",
    "dump(grid7.best_estimator_, 'MLP_best_estimator_augmented_speech_grid7.joblib', compress = 1) # Saving the best estimators\n",
    "dump(grid7.cv_results_, 'MLP_CV_result_augmented_speech_grid7.pkl')                           # Saving the whole object\n",
    "dump(grid7, 'MLP_whole_object_augmented_speech_grid7.pkl')                                    # Saving the whole object\n",
    "\n",
    "\n",
    "### Visualisation of search performance\n",
    "df_grid7 = load('MLP_CV_result_augmented_speech_grid7.pkl')\n",
    "df_grid7 = pd.DataFrame(df_grid7)\n",
    "# Create a 3d scatter plot of the data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x_points = df_grid7['param_alpha']\n",
    "y_points = df_grid7['mean_score_time']\n",
    "z_points = df_grid7['mean_test_score']\n",
    "colour = df_grid7['rank_test_score']\n",
    "sctt = ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='jet');\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Mean score time')\n",
    "ax.set_zlabel('Score')\n",
    "fig.colorbar(sctt, shrink=0.5)\n",
    "ax.view_init(elev=15, azim=30)\n",
    "ax.text2D(0, 1, \"3D visualisation of MLP Grid7 randomized SearchCV performance on the speech data\", transform=ax.transAxes)\n",
    "fig.savefig(\"grid7_3d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6 Performing MLP classification using optimal parameters on speech channel of augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP classifer with best parameters from the grid search with the scaled data\n",
    "\n",
    "model14 = MLPClassifier(\n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    alpha=0.001, \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    batch_size=256, \n",
    "    epsilon=1e-08, \n",
    "    hidden_layer_sizes=(180,), \n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    early_stopping=True, # without early stopping\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "model14.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "\n",
    "print(f'MLP Model\\'s accuracy on training set is {100*model14.score(X_train_scaled_augmented_speech, y_train_augmented_speech):.2f}%')\n",
    "print(f'MLP Model\\'s accuracy on test set is {100*model14.score(X_test_scaled_augmented_speech, y_test_augmented_speech):.2f}%')\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model14, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model14, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model14, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model14, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model14, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model14, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "    viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of optimised MLP classifier with optimal parameters on speech channel', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model14.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 RandomizedSearchCV to tune MLP parameters using the song channel of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################ Do not run ###################################################################\n",
    "# Initialize the MLP Classifier and choose parameters we want to keep constant\n",
    "tic = time.perf_counter()\n",
    "\n",
    "k = StratifiedKFold(n_splits=3, shuffle=False)\n",
    "mlp = MLPClassifier(\n",
    "    # tune batch size later \n",
    "    batch_size=256,  \n",
    "    # keep random state constant to accurately compare subsequent models\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Choose the grid of hyperparameters we want to use for Grid Search to build our candidate models\n",
    "param_grid8 = {\n",
    "    'hidden_layer_sizes': [(8,), (180,), (300,),(100,50,),(10,10,10)], \n",
    "    'activation': ['tanh','relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'epsilon': [1e-08, 0.1],\n",
    "    'learning_rate': ['adaptive', 'constant'],\n",
    "}\n",
    "\n",
    "grid8 = RandomizedSearchCV(mlp, param_distributions = param_grid8, n_iter = 20, n_jobs = -1, cv = k, scoring = \"accuracy\") \n",
    "grid8.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "\n",
    "#print(grid8.cv_results_)\n",
    "print(grid8.best_params_)\n",
    "print(grid8.score(X_test_scaled_augmented_song, y_test_augmented_song))\n",
    "print()\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(f\"Time to run the RandomizedSearchCV for MLP is {toc - tic:0.4f} seconds\")\n",
    "print()\n",
    "\n",
    "dump(grid8.best_estimator_, 'MLP_best_estimator_augmented_song_grid8.joblib', compress = 1) # Saving the best estimators\n",
    "dump(grid8.cv_results_, 'MLP_CV_result_augmented_song_grid8.pkl')                           # Saving the whole object\n",
    "dump(grid8, 'MLP_whole_object_augmented_song_grid8.pkl')                                    # Saving the whole object\n",
    "\n",
    "### 3D visualisation of search performance\n",
    "df_grid8 = load('MLP_CV_result_augmented_song_grid8.pkl')\n",
    "df_grid8 = pd.DataFrame(df_grid8)\n",
    "# Create a 3d scatter plot of the data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x_points = df_grid8['param_alpha']\n",
    "y_points = df_grid8['mean_score_time']\n",
    "z_points = df_grid8['mean_test_score']\n",
    "colour = df_grid8['rank_test_score']\n",
    "sctt = ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='jet');\n",
    "ax.set_xlabel('Alpha')\n",
    "ax.set_ylabel('Mean score time')\n",
    "ax.set_zlabel('Score')\n",
    "fig.colorbar(sctt, shrink=0.5)\n",
    "ax.view_init(elev=15, azim=30)\n",
    "ax.text2D(0, 1, \"3D visualisation of MLP Grid8 randomized SearchCV performance on the song data\", transform=ax.transAxes)\n",
    "fig.savefig(\"grid8_3d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.8 Performing MLP classification using optimal parameters on song channel of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP classifer with best parameters from the grid search with the scaled data\n",
    "\n",
    "model15 = MLPClassifier(\n",
    "    activation='tanh', \n",
    "    solver='adam', \n",
    "    alpha=0.001, \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    batch_size=256, \n",
    "    epsilon=1e-08, \n",
    "    hidden_layer_sizes=(180,), \n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1000,\n",
    "    early_stopping=True, # without early stopping\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "model15.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "\n",
    "print(f'MLP Model\\'s accuracy on training set is {100*model15.score(X_train_scaled_augmented_song, y_train_augmented_song):.2f}%')\n",
    "print(f'MLP Model\\'s accuracy on test set is {100*model15.score(X_test_scaled_augmented_song, y_test_augmented_song):.2f}%')\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(3, 2,figsize=(25, 12))\n",
    "set_aesthetic(palette='paired', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "visualgrid = [\n",
    "    CVScores(model15, cv=3, scoring='f1_weighted', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][0]),\n",
    "    LearningCurve(model15, cv=3, scoring='f1_weighted', train_sizes=np.linspace(.1, 1.0, 5), n_jobs=4, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[0][1]),\n",
    "    ClassificationReport(model15, support=True, cmap='GnBu', classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][0]),  \n",
    "    ClassPredictionError(model15, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[1][1]),\n",
    "    PrecisionRecallCurve(model15, per_class=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][0]),\n",
    "    ROCAUC(model15, classes=['neutral','calm','happy', 'sad','angry','fearful'], ax=axes[2][1])\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "    viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "    viz.finalize()\n",
    "f.suptitle('Performance of optimised MLP classifier with early stopping on standard scaled and augmented song dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "viz.show(outpath=\"model15.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.9 Confusion matrix of optimised SVM and MLP on speech channel of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2, figsize=(25, 12))\n",
    "set_aesthetic(palette='dark', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "classes=['neutral','calm','happy', 'sad','angry','fearful']\n",
    "visualgrid = [\n",
    "    ConfusionMatrix(model12, cmap='GnBu', classes=classes, title=\"Optimised SVM classification on augmented speech data\", ax=ax1),\n",
    "    ConfusionMatrix(model14, cmap='GnBu', classes=classes, title=\"Optimised MLP classification on augmented speech data\", ax=ax2),\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "    viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "    viz.finalize()\n",
    "f.suptitle('Confusion matrix for optimised SVM and MLP models on augmented speech data', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "f.savefig(\"Confusion_matrix4_MLP_SVM_augmented_speech.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.10 Confusion matrix of optimised SVM and MLP on song channel of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2, figsize=(25, 12))\n",
    "set_aesthetic(palette='dark', font='Arial', font_scale=2, color_codes=True, rc=None)\n",
    "classes=['neutral','calm','happy', 'sad','angry','fearful']\n",
    "visualgrid = [\n",
    "    ConfusionMatrix(model13, cmap='GnBu', classes=classes, title=\"Optimised SVM classification on augmented song data\", ax=ax1),\n",
    "    ConfusionMatrix(model15, cmap='GnBu', classes=classes, title=\"Optimised MLP classification on augmented song data\", ax=ax2),\n",
    "]\n",
    "\n",
    "for viz in visualgrid:\n",
    "    viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "    viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "    viz.finalize()\n",
    "f.suptitle('Confusion matrix for optimised SVM and MLP models on augmented song data', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "f.savefig(\"Confusion_matrix4_MLP_SVM_augmented_song.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.11 Comparative performance of SVM and MLP classification using speech channel of augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=2)\n",
    "set_palette('paired')\n",
    "f, ((ax1, ax2, ax3,), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(25, 12))\n",
    "viz = ClassificationReport(model12, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"SVM classification report for augmented speech data\", ax=ax1)\n",
    "viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "viz.finalize()\n",
    "viz = ClassPredictionError(model12, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"SVM prediction error for augmented speech data\", ax=ax2)\n",
    "viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model12, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"SVM confusion matrix for augmented speech data\", ax=ax3)\n",
    "viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "viz.finalize()\n",
    "viz = ClassificationReport(model14, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"MLP classification report for augmented speech data\", ax=ax4)\n",
    "viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "viz.finalize()\n",
    "viz = ClassPredictionError(model14, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"MLP prediction error for augmented speech data\", ax=ax5)\n",
    "viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model14, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"MLP confusion matrix augmented speech data\", ax=ax6)\n",
    "viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "viz.finalize()\n",
    "f.suptitle('Comparative performance of optimised SVM amd MLP classification using speech channel of augmented data', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "f.savefig(\"Comparative_performance3.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.12 Comparative performance of optimised SVM and MLP classification using song channel of augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=2)\n",
    "set_palette('paired')\n",
    "f, ((ax1, ax2, ax3,), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(25, 12))\n",
    "viz = ClassificationReport(model13, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"SVM classification report for augmented song data\", ax=ax1)\n",
    "viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "viz.finalize()\n",
    "viz = ClassPredictionError(model13, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"SVM prediction error for augmented song data\", ax=ax2)\n",
    "viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model13, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"SVM confusion matrix for augmented song data\", ax=ax3)\n",
    "viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "viz.finalize()\n",
    "viz = ClassificationReport(model15, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"MLP classification report for augmented song data\", ax=ax4)\n",
    "viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "viz.finalize()\n",
    "viz = ClassPredictionError(model15, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"MLP prediction error for augmented song data\", ax=ax5)\n",
    "viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "viz.finalize()\n",
    "viz = ConfusionMatrix(model15, support=True, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"MLP confusion matrix for augmented song data\", ax=ax6)\n",
    "viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "viz.finalize()\n",
    "f.suptitle('Comparative performance of optimised SVM amd MLP classification using song channel of augmented data', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "f.savefig(\"Comparative_performance4.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.13 plotting ROC/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper', font_scale=2)\n",
    "set_palette('paired')\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(25, 12))\n",
    "viz = ROCAUC(model12, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"SVM ROC/AUC for augmented speech data\", ax=ax1)\n",
    "viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "viz.finalize()\n",
    "viz = ROCAUC(model13, classes=['neutral','calm','happy', 'sad','angry','fearful'], title=\"SVM ROC/AUC for augmented song data\", ax=ax2)\n",
    "viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "viz.finalize()\n",
    "viz = ROCAUC(model14, classes=['neutral','calm','happy', 'sad','angry','fearful','disgust','surprised'], cmap='GnBu', title=\"MLP ROC/AUC for augmented speech data\", ax=ax3)\n",
    "viz.fit(X_train_scaled_augmented_speech, y_train_augmented_speech)\n",
    "viz.score(X_test_scaled_augmented_speech, y_test_augmented_speech)\n",
    "viz.finalize()\n",
    "viz = ROCAUC(model15, classes=['neutral','calm','happy', 'sad','angry','fearful'], cmap='GnBu', title=\"MLP ROC/AUC for augmented song data\", ax=ax4)\n",
    "viz.fit(X_train_scaled_augmented_song, y_train_augmented_song)\n",
    "viz.score(X_test_scaled_augmented_song, y_test_augmented_song)\n",
    "viz.finalize()\n",
    "f.suptitle('Comparison of ROC/AUC of optimised SVM amd MLP emotion classification using speech and song dataset', fontsize=32, weight=\"bold\");\n",
    "plt.subplots_adjust(top=0.91)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "f.savefig(\"Comparative_performance5.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Processing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
